{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ASL YOLO Notebook\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1BwSkvGjwLQV3Ju3WMQlOvwvxQJfIlJZ0?usp=sharing)\n",
        "[![Open In GitHub](https://badgen.net/badge/icon/github?icon=github&label)](https://github.com/priyanshumahey/ASL-OpenCV-Recognition)\n",
        "\n",
        "This notebook covers how to train the YOLOV5 deep neural network using an ASL dataset taken from roboflow. From there, the goal is to use the trained model which we can implement onto opencv."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparing the Model and Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATvjXCxBXatn"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#^ This ignores the output of the cell\n",
        "\n",
        "#Cloning yolov5\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -U coremltools>=4.1 onnx>=1.9.0 scikit-learn==0.19.2\n",
        "\n",
        "## Change torch to troch == 1.7.0 in requirements\n",
        "## If that doesn't work, change to \n",
        "#install torch==1.11,\n",
        "#torchvision==0.12,\n",
        "#torchtext==0.12,\n",
        "#torchaudio==0.11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2Ltk2gff7Y-"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwbIpkSpYIef"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "#This installs the dataset itself\n",
        "%cd /content\n",
        "!curl -L \"https://public.roboflow.com/ds/ZOEdOs1dLv?key=4ZGGms5agy\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
        "\n",
        "## If prompted, it may want you to replace the files you already have may require you to select if you want to replace them.\n",
        "## [y]es, [n]o, [A]ll, [N]one, [r]ename: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup\n",
        "\n",
        "We'll start off by figuring out exactly what we'd like to import. From there, we'll set up pytorch and make CUDA is active. On Google Colab, we'd want to switch runtime to GPU to significantly speed up the entire process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7Fbb5VyY1XB",
        "outputId": "3d4adb8e-b25a-44b5-d772-63c297b0266d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import yaml\n",
        "from IPython.display import Image, clear_output\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll then want to import in data.yaml to access what the dataset actually looks like and gain a deeper look into the structure of the dataset at hand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNx05GMkZ3Gu",
        "outputId": "fac1d443-ab30-486e-a140-7592327de634"
      },
      "outputs": [],
      "source": [
        "%cat data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVpsLv1OdEFp"
      },
      "outputs": [],
      "source": [
        "with open(\"data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])\n",
        "with open(\"data.yaml\", 'r') as stream:\n",
        "    names = str(yaml.safe_load(stream)['names'])\n",
        "\n",
        "print('num_classes: %s' %num_classes)\n",
        "print('names: %s' %names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAhX2Av1echd",
        "outputId": "0bfa8c4d-bbda-4ecc-c44c-697f72159a82"
      },
      "outputs": [],
      "source": [
        "%cat /content/yolov5/models/yolov5s.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#customize iPython writefile so we can write variables\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using the YOLO Model\n",
        "\n",
        "We'll be using a custom version of the yolov5 structure and here we simply create a new template file for the yolov5 algorithm to run off of and make it into a yaml file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBE3h5PtegnK"
      },
      "outputs": [],
      "source": [
        "%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "depth_multiple: 0.33  # model depth multiple\n",
        "width_multiple: 0.50  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, BottleneckCSP, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 9, BottleneckCSP, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, BottleneckCSP, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we'll actually train the actual yolov5 network using the dataset. We add in all the arguments we'd like to use and then train it. On Google Colab with GPU, this roughly takes 30 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Q-eF9aRfLRh",
        "outputId": "2b293b7f-f6c1-446f-9796-928f4376f3dd"
      },
      "outputs": [],
      "source": [
        "# train yolov5s on custom data for 100 epochs\n",
        "# time its performance\n",
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!python train.py --img 416 --batch 16 --epochs 100 --data '../data.yaml' --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Looking at the Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From there, we can load in tensorboard to view the results of the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll also view some regular graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Image(filename='/content/yolov5/runs/train/yolov5s_results/results.png', width=1000)  # view results.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also then view the results of the program by viewing what the real labels look like and then compare that to some predictions made by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7l56A3EhfjO",
        "outputId": "d001a614-7773-4f2a-df9d-b5e7946a6a51"
      },
      "outputs": [],
      "source": [
        "!cd ./\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 934
        },
        "id": "DUHIhSQyhUkq",
        "outputId": "22f82d0a-797d-46cd-fd9b-75e6a91b878d"
      },
      "outputs": [],
      "source": [
        "#The actual real data\n",
        "print(\"Real Labels\")\n",
        "Image(filename='/content/yolov5/runs/train/yolov5s_results/val_batch2_labels.jpg', width=900)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 934
        },
        "id": "mcgjvwqBZB7y",
        "outputId": "d132dfd6-6276-42f7-d306-481195f711d2"
      },
      "outputs": [],
      "source": [
        "#Predictions on the data\n",
        "print(\"Predicted Labels\")\n",
        "Image(filename='/content/yolov5/runs/train/yolov5s_results/val_batch2_pred.jpg', width=900)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exporting the Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9mQmV0NZB2E",
        "outputId": "01de0855-6ec6-4a5e-e1cb-24115c0c40bd"
      },
      "outputs": [],
      "source": [
        "# trained weights are saved by default in our weights folder\n",
        "%ls runs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3pxRgWOZKPF",
        "outputId": "7ae873bc-dcbe-47e5-9dbd-b4b9db14abab"
      },
      "outputs": [],
      "source": [
        "%ls runs/train/yolov5s_results/weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFaCySG8Zbdt",
        "outputId": "5cb96ba5-c2aa-4559-98dd-0af54a082414"
      },
      "outputs": [],
      "source": [
        "!python export.py --weights /content/yolov5/runs/train/yolov5s_results/weights/best.pt --img 640 --batch 1 --include 'onnx' # export at 640x640 with batch size 1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRaMUXn8j4q7"
      },
      "outputs": [],
      "source": [
        "best_weights = \"/content/yolov5/runs/train/yolov5s_results/weights/best.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaVslMapj4mI",
        "outputId": "cce70bb1-2cab-4490-b44a-b7d40d75d135"
      },
      "outputs": [],
      "source": [
        "%cd /content/yolov5/\n",
        "!python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 416 --conf 0.4 --source ../test/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gq6f90ErkKhy",
        "outputId": "ef355e68-6bfe-48e6-88a4-18b55e596349"
      },
      "outputs": [],
      "source": [
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing on your own images\n",
        "\n",
        "Under `/content/yolov5/runs/detect/exp`, you'll need to put down the images you want detected (in jpg format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp7/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ASL.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
